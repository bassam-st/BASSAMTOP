# bassam_core/workers/core_worker.py
# -*- coding: utf-8 -*-
"""
ðŸ”¥ Bassam Core Worker â€“ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
ÙŠØ±Ø¨Ø· Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ø¨Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.
ÙŠÙÙ†ÙÙ‘Ø° Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ÙŠØ¯ÙˆÙŠØ© (Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…) + Ø§Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„.
"""

import os
import json
import time
import threading
from datetime import datetime
from typing import List, Dict, Any, Optional
from duckduckgo_search import DDGS

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ†
ROOT_DIR = os.path.dirname(os.path.dirname(__file__))
DATA_DIR = os.path.join(ROOT_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

NEWS_PATH = os.path.join(DATA_DIR, "news.jsonl")      # Ø£Ø±Ø´ÙŠÙ Ø§Ù„ØªØ¹Ù„Ù‘Ù…
QUEUE_PATH = os.path.join(DATA_DIR, "queue.jsonl")    # ØµÙ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
KNOW_PATH = os.path.join(DATA_DIR, "knowledge.jsonl") # Ù…Ø¹Ø±ÙØ© ØªØ±Ø§ÙƒÙ…ÙŠØ©

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ ÙƒÙ„ 30 Ø¯Ù‚ÙŠÙ‚Ø©)
INTERVAL_MIN = int(os.getenv("LEARN_INTERVAL_MIN", "30"))
INTERVAL_SEC = int(os.getenv("LEARN_INTERVAL_SEC", "0"))
RUN_IMMEDIATELY = os.getenv("LEARN_RUN_IMMEDIATELY", "1") == "1"

# Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø°Ø§ØªÙŠ
TOPICS = [
    "ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© 2025",
    "Ø£ÙØ·Ø± Python Ù„Ø¨Ù†Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø§Øª Ø¨Ø±Ù…Ø¬ÙŠØ© FastAPI Ùˆ Flask",
    "ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„ÙˆÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AsyncIO",
    "ØªØµÙ…ÙŠÙ… Chatbots Ø°ÙƒÙŠØ© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ RAG Ùˆ LLMs",
    "Ø£ÙØ¶Ù„ Ù…Ù…Ø§Ø±Ø³Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ´ÙÙŠØ± ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„ÙˆÙŠØ¨",
    "Ø§Ø³ØªØ®Ø¯Ø§Ù… APIs Ù…ÙØªÙˆØ­Ø© Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰",
    "ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„Ø¹Ù…Ù„",
]

# -------------------------
# Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ØªØ®Ø²ÙŠÙ†
# -------------------------
def _append_jsonl(path: str, obj: Dict[str, Any]) -> None:
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")

def _read_jsonl(path: str, limit: Optional[int] = None) -> List[Dict[str, Any]]:
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8") as f:
        lines = f.read().splitlines()
    if limit:
        lines = lines[-limit:]
    return [json.loads(x) for x in lines]

# -------------------------
# ØµÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Worker Queue)
# -------------------------
_queue_lock = threading.Lock()
_queue: List[Dict[str, Any]] = []
_last_results_lock = threading.Lock()
_last_results: List[Dict[str, Any]] = []
_running = threading.Event()

def enqueue_task(q: str) -> None:
    """Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø¨Ø­Ø«/ØªØ¹Ù„Ù…)."""
    item = {"q": q.strip(), "ts": datetime.utcnow().isoformat()}
    with _queue_lock:
        _queue.append(item)
    _append_jsonl(QUEUE_PATH, item)

def query_index() -> List[str]:
    """Ø¹Ø±Ø¶ Ø¢Ø®Ø± Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
    with _queue_lock:
        return [x["q"] for x in _queue[-15:]]

def get_status() -> Dict[str, Any]:
    """Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ù…Ø¬Ø¯ÙˆÙ„."""
    return {
        "running": _running.is_set(),
        "interval_min": INTERVAL_MIN,
        "interval_sec": INTERVAL_SEC,
        "queue_size": len(_queue),
        "topics": TOPICS,
    }

def get_latest_results(limit: int = 10) -> List[Dict[str, Any]]:
    """Ø¹Ø±Ø¶ Ø£Ø­Ø¯Ø« Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø°Ø§ØªÙŠ."""
    docs = _read_jsonl(NEWS_PATH, limit=limit)
    return list(reversed(docs))

# -------------------------
# ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªÙ„Ø®ÙŠØµ
# -------------------------
def _ddg_search(q: str, n: int = 6) -> List[Dict[str, str]]:
    results = []
    try:
        with DDGS() as d:
            for r in d.text(q, max_results=n, region="sa-ar"):
                results.append({
                    "title": r.get("title", ""),
                    "href": r.get("href", ""),
                    "snippet": r.get("body", "")[:250],
                })
    except Exception as e:
        results.append({"title": "SearchError", "href": "", "snippet": str(e)})
    return results

def _summarize(q: str, results: List[Dict[str, str]]) -> str:
    """ØªÙ„Ø®ÙŠØµ Ù…Ø¨Ø³Ø· Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬."""
    lines = [f"- {r['title']}: {r['snippet']}" for r in results[:5]]
    if not lines:
        lines = ["- Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬."]
    return f"ðŸ“˜ Ù…Ù„Ø®Øµ Ø­ÙˆÙ„ Â«{q}Â»:\n" + "\n".join(lines)

def _learn_once(q: str) -> Dict[str, Any]:
    """ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© ØªØ¹Ù„Ù… ÙˆØ§Ø­Ø¯Ø© (Ø¨Ø­Ø« + ØªÙ„Ø®ÙŠØµ + ØªØ®Ø²ÙŠÙ†)."""
    results = _ddg_search(q)
    summary = _summarize(q, results)
    doc = {
        "query": q,
        "summary": summary,
        "timestamp": datetime.utcnow().isoformat(),
        "results": results,
    }
    _append_jsonl(NEWS_PATH, doc)
    _append_jsonl(KNOW_PATH, doc)
    return doc

def _drain_queue() -> None:
    """ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ØµÙ."""
    global _queue
    with _queue_lock:
        if not _queue:
            return
        batch = _queue[:]
        _queue = []
    for item in batch:
        _learn_once(item["q"])

# -------------------------
# Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ (Scheduler)
# -------------------------
class Scheduler:
    def __init__(self, minutes=INTERVAL_MIN, seconds=INTERVAL_SEC, run_now=RUN_IMMEDIATELY):
        self.interval = minutes * 60 + seconds
        self.run_now = run_now
        self.stop_event = threading.Event()
        self.thread = threading.Thread(target=self._loop, daemon=True)

    def start(self):
        print(f"ðŸ•’ Scheduler started (every {self.interval//60} min)")
        self.thread.start()

    def stop(self):
        self.stop_event.set()
        print("ðŸ›‘ Scheduler stopped")

    def _loop(self):
        if self.run_now:
            self._tick()
        while not self.stop_event.is_set():
            for _ in range(int(self.interval * 10)):
                if self.stop_event.is_set():
                    return
                time.sleep(0.1)
            self._tick()

    def _tick(self):
        print(f"ðŸ” Running auto-learning cycle ({datetime.utcnow().isoformat()})")
        _drain_queue()
        for topic in TOPICS:
            try:
                _learn_once(topic)
            except Exception as e:
                _append_jsonl(NEWS_PATH, {"topic": topic, "error": str(e), "ts": datetime.utcnow().isoformat()})
        print("âœ… Cycle complete â€” knowledge updated.")

# -------------------------
# Ø±Ø¨Ø· Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ø¨Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„
# -------------------------
_SCHED: Optional[Scheduler] = None

def start_scheduler() -> None:
    """ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (startup event)."""
    global _SCHED
    if _SCHED:
        return
    _running.set()
    _SCHED = Scheduler()
    _SCHED.start()
    print("ðŸ”¥ Bassam Core Worker linked to Scheduler â€” running automatically!")

# ØªØ´ØºÙŠÙ„ ÙŠØ¯ÙˆÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ
if __name__ == "__main__":
    start_scheduler()
    try:
        while True:
            time.sleep(5)
    except KeyboardInterrupt:
        _SCHED.stop()
